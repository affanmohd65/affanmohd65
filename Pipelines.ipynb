{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJ55kjoQ0+tkaijNIJ706s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/affanmohd65/affanmohd65/blob/main/Pipelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3IDrbVBpN1l-"
      },
      "outputs": [],
      "source": [
        "# Install Java (required for Spark)\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download latest Spark 3.5.x (Hadoop 3)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "\n",
        "# Extract Spark\n",
        "!tar -xzf spark-3.5.1-bin-hadoop3.tgz\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\"\n",
        "\n",
        "# 5️⃣ Install findspark\n",
        "!pip install -q findspark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ColabSparkPipeline\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "IJDujvZaOIzb",
        "outputId": "814d9ddf-5642-4a4c-baa0-0fcc0b06b8d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f3e3cf2fc20>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://b7e0f8455e1a:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>ColabSparkPipeline</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (65, 120),\n",
        "    (70, 150),\n",
        "    (72, 160),\n",
        "    (60, 110),\n",
        "    (80, 200),\n",
        "    (85, 220),\n",
        "    (75, 180),\n",
        "    (68, 140)\n",
        "]\n",
        "\n",
        "columns = [\"height\", \"weight\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNQrNcrHYfbu",
        "outputId": "3c7cd6bc-26a8-4b71-a803-4af4157795a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+\n",
            "|height|weight|\n",
            "+------+------+\n",
            "|    65|   120|\n",
            "|    70|   150|\n",
            "|    72|   160|\n",
            "|    60|   110|\n",
            "|    80|   200|\n",
            "|    85|   220|\n",
            "|    75|   180|\n",
            "|    68|   140|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing for pipeline stages\n",
        "# we will use -> VectorAssembler = combine features ,StanderdScaler = standerd features\n",
        "# LinearRegression = train a simple regression model\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "assembler = VectorAssembler(inputCols=[\"height\"], outputCol=\"features_unscaled\")\n",
        "\n",
        "scaler = StandardScaler(inputCol=\"features_unscaled\", outputCol=\"features\")\n",
        "\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"weight\")\n",
        "\n",
        "pl = Pipeline(stages = [assembler, scaler, lr])"
      ],
      "metadata": {
        "id": "jNKGKEl4Yxkx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed = 42)\n",
        "\n",
        "model = pl.fit(train_df)\n",
        "\n",
        "predictions = model.transform(test_df)\n",
        "predictions.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_OV6tK2dyNw",
        "outputId": "dd6ff61b-1adb-431e-948c-8057286d0f28"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-----------------+-------------------+-----------------+\n",
            "|height|weight|features_unscaled|           features|       prediction|\n",
            "+------+------+-----------------+-------------------+-----------------+\n",
            "|    70|   150|           [70.0]|[7.540990499768686]|151.7485493230173|\n",
            "|    68|   140|           [68.0]|[7.325533628346724]|142.3945841392648|\n",
            "+------+------+-----------------+-------------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "evaluator = RegressionEvaluator(labelCol=\"weight\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NgwryOjeaH4",
        "outputId": "deab8887-1b6b-421a-9376-3cc993097721"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = model.stages[-1]\n",
        "print(\"Intercept:\", lr_model.intercept)\n",
        "print(\"Coefficient:\", lr_model.coefficients)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2Y8gVUGelKK",
        "outputId": "34e11a9f-ebe3-49ba-ab21-8df80e4ed4e8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercept: -175.64023210832153\n",
            "Coefficient: [43.41455959152597]\n"
          ]
        }
      ]
    }
  ]
}